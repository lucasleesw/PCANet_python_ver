{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PCANet_experimen_on_MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "la7IEadGgyTw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import svm\n",
        "s= svm.SVC(C=10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "509ePZQz7pyb",
        "colab_type": "code",
        "outputId": "3ab58548-37fc-4737-fde2-78a912dd90f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/content/drive/\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxDr8Cby87Qs",
        "colab_type": "code",
        "outputId": "cf53e757-50b3-4071-b781-0f90251e5524",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "cd '/content/drive/My Drive/pcanet/PCANet_python_ver'"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/pcanet/PCANet_python_ver\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZtbksqLqlhHb",
        "colab_type": "code",
        "outputId": "abdcbe3d-871c-42a8-baa1-329511dee353",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[0m\u001b[01;34mdata\u001b[0m/            LICENSE                      PCANet-MNIST.ipynb  README.md\n",
            "data_loader2.py  mnist_background_images.pkl  PCANet.py\n",
            "data_loader.py   mnist_background_random.pkl  playground.ipynb\n",
            "interface.py     mnist_basic.pkl              \u001b[01;34m__pycache__\u001b[0m/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xH491Ky8Wgd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "! git add -A"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50xkDcI56lKS",
        "colab_type": "code",
        "outputId": "a9033fc5-61a3-4982-8345-c7841a81e1e2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        }
      },
      "source": [
        "! git commit -m \"colab test1\""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[master 5f05721] colab test1\n",
            " 2 files changed, 1 insertion(+), 1 deletion(-)\n",
            " create mode 100644 .gitignore\n",
            " rewrite PCANet-MNIST.ipynb (72%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aWhnzPcC0dfj",
        "colab_type": "code",
        "outputId": "d20380d7-ddb3-48f7-f788-63a383c795f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "! git pull https://github.com/lucasleesw/PCANet_python_ver"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "remote: Enumerating objects: 4, done.\u001b[K\n",
            "remote: Counting objects:  25% (1/4)\u001b[K\rremote: Counting objects:  50% (2/4)\u001b[K\rremote: Counting objects:  75% (3/4)\u001b[K\rremote: Counting objects: 100% (4/4)\u001b[K\rremote: Counting objects: 100% (4/4), done.\u001b[K\n",
            "remote: Compressing objects:  50% (1/2)\u001b[K\rremote: Compressing objects: 100% (2/2)\u001b[K\rremote: Compressing objects: 100% (2/2), done.\u001b[K\n",
            "remote: Total 3 (delta 1), reused 3 (delta 1), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (3/3), done.\n",
            "From https://github.com/lucasleesw/PCANet_python_ver\n",
            " * branch            HEAD       -> FETCH_HEAD\n",
            "Updating 5f05721..b40984d\n",
            "Fast-forward\n",
            " colab_CIFAR10.ipynb | 770 \u001b[32m++++++++++++++++++++++++++++++++++++++++++++++++++++\u001b[m\n",
            " 1 file changed, 770 insertions(+)\n",
            " create mode 100644 colab_CIFAR10.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQp3b1qsq1x1",
        "colab_type": "code",
        "outputId": "350cfdb6-2372-4a79-a3df-3c4bbdc37c20",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 153
        }
      },
      "source": [
        "! git push origin master"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Counting objects: 4, done.\n",
            "Delta compression using up to 2 threads.\n",
            "Compressing objects:  33% (1/3)   \rCompressing objects:  66% (2/3)   \rCompressing objects: 100% (3/3)   \rCompressing objects: 100% (3/3), done.\n",
            "Writing objects:  25% (1/4)   \rWriting objects:  50% (2/4)   \rWriting objects:  75% (3/4)   \rWriting objects: 100% (4/4)   \rWriting objects: 100% (4/4), 1.87 KiB | 478.00 KiB/s, done.\n",
            "Total 4 (delta 2), reused 0 (delta 0)\n",
            "remote: Resolving deltas: 100% (2/2), completed with 2 local objects.\u001b[K\n",
            "To https://github.com/lucasleesw/PCANet_python_ver.git\n",
            "   5036e3d..5f05721  master -> master\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lida9oOAIWqm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import os\n",
        "from PCANet import *\n",
        "from data_loader import *\n",
        "import sys\n",
        "import torch\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PZURe6udjFhG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def load_mnist_2_0(dir_name):\n",
        "  train_name = dir_name + \"_train.amat\"\n",
        "  test_name = dir_name + \"_test.amat\"\n",
        "\n",
        "  train_path = os.path.join(os.path.dirname(os.getcwd()),'mnist_2.0', dir_name, train_name)\n",
        "  test_path = os.path.join(os.path.dirname(os.getcwd()),'mnist_2.0', dir_name, test_name)\n",
        "\n",
        "  train_data = np.loadtxt(train_path)\n",
        "  test_data = np.loadtxt(test_path)\n",
        "\n",
        "  data_train = train_data[:, :-1] / 1.0\n",
        "  data_train = data_train.reshape((data_train.shape[0],28,28))\n",
        "  label_train = train_data[:, -1:].flatten()\n",
        "\n",
        "  data_test = test_data[:, :-1] / 1.0\n",
        "  data_test = data_test.reshape((data_test.shape[0],28,28))\n",
        "  label_test = test_data[:, -1:].flatten()\n",
        "  \n",
        "  return data_train, label_train, data_test, label_test"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CTGeQ92nVNI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images, train_labels, test_images, test_labels = load_mnist_2_0('mnist_background_images')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q9Yk22S2bPbY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_images = train_images[:10000]\n",
        "train_labels = train_labels[:10000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKzWoSGibegQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_images = test_images[:10000]\n",
        "test_labels = test_labels[:10000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaDUS3sZA3x0",
        "colab_type": "code",
        "outputId": "69f4e4de-f83a-4661-a385-0eb136c53f75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "net = PCANet(k1=7, k2=7, L1=8, L2=8, block_size=7, overlapping_radio=0)\n",
        "net.fit(train_images, train_labels)\n",
        "prediction = net.predict(test_images)\n",
        "print(accuracy_score(test_labels, prediction))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================\n",
            "calculating L1_stage filters\n",
            "0 th picture\n",
            "shape of L1_stage filters: (8, 7, 7)\n",
            "shape of L1 stage convolution results: (80000, 28, 28)\n",
            "====================\n",
            "calculating L2_stage filters\n",
            "0 th picture\n",
            "10000 th picture\n",
            "20000 th picture\n",
            "30000 th picture\n",
            "40000 th picture\n",
            "50000 th picture\n",
            "60000 th picture\n",
            "70000 th picture\n",
            "shape of L2_stage filters: (8, 7, 7)\n",
            "====================\n",
            "extracting 0 th feature\n",
            "extracting 1000 th feature\n",
            "extracting 2000 th feature\n",
            "extracting 3000 th feature\n",
            "extracting 4000 th feature\n",
            "extracting 5000 th feature\n",
            "extracting 6000 th feature\n",
            "extracting 7000 th feature\n",
            "extracting 8000 th feature\n",
            "extracting 9000 th feature\n",
            "length of feature: 32768\n",
            "====================\n",
            "features extracted, SVM training\n",
            "====================\n",
            "predicting 0 th label\n",
            "predicting 500 th label\n",
            "predicting 1000 th label\n",
            "predicting 1500 th label\n",
            "predicting 2000 th label\n",
            "predicting 2500 th label\n",
            "predicting 3000 th label\n",
            "predicting 3500 th label\n",
            "predicting 4000 th label\n",
            "predicting 4500 th label\n",
            "predicting 5000 th label\n",
            "predicting 5500 th label\n",
            "predicting 6000 th label\n",
            "predicting 6500 th label\n",
            "predicting 7000 th label\n",
            "predicting 7500 th label\n",
            "predicting 8000 th label\n",
            "predicting 8500 th label\n",
            "predicting 9000 th label\n",
            "predicting 9500 th label\n",
            "====================\n",
            "0.864\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ9kSxnD8StA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def do_it(dir_name):\n",
        "  train_images, train_labels, test_images, test_labels = load_mnist_2_0(dir_name)\n",
        "  train_images = train_images[:10000]\n",
        "  train_labels = train_labels[:10000]\n",
        "  test_images = test_images[:10000]\n",
        "  test_labels = test_labels[:10000]\n",
        "  net = PCANet(k1=7, k2=7, L1=8, L2=8, block_size=7, overlapping_radio=0)\n",
        "  net.fit(train_images, train_labels)\n",
        "  prediction = net.predict(test_images)\n",
        "  print(accuracy_score(test_labels, prediction))\n",
        "  model_name = dir_name + '.pkl'\n",
        "  torch.save(net, model_name)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SVlw7ky99Whv",
        "colab_type": "code",
        "outputId": "8f19b76f-b5c7-464f-cc72-14b74e277b10",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        }
      },
      "source": [
        "do_it('mnist_background_random')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "====================\n",
            "calculating L1_stage filters\n",
            "0 th picture\n",
            "shape of L1_stage filters: (8, 7, 7)\n",
            "shape of L1 stage convolution results: (80000, 28, 28)\n",
            "====================\n",
            "calculating L2_stage filters\n",
            "0 th picture\n",
            "10000 th picture\n",
            "20000 th picture\n",
            "30000 th picture\n",
            "40000 th picture\n",
            "50000 th picture\n",
            "60000 th picture\n",
            "70000 th picture\n",
            "shape of L2_stage filters: (8, 7, 7)\n",
            "====================\n",
            "extracting 0 th feature\n",
            "extracting 1000 th feature\n",
            "extracting 2000 th feature\n",
            "extracting 3000 th feature\n",
            "extracting 4000 th feature\n",
            "extracting 5000 th feature\n",
            "extracting 6000 th feature\n",
            "extracting 7000 th feature\n",
            "extracting 8000 th feature\n",
            "extracting 9000 th feature\n",
            "length of feature: 32768\n",
            "====================\n",
            "features extracted, SVM training\n",
            "====================\n",
            "predicting 0 th label\n",
            "predicting 500 th label\n",
            "predicting 1000 th label\n",
            "predicting 1500 th label\n",
            "predicting 2000 th label\n",
            "predicting 2500 th label\n",
            "predicting 3000 th label\n",
            "predicting 3500 th label\n",
            "predicting 4000 th label\n",
            "predicting 4500 th label\n",
            "predicting 5000 th label\n",
            "predicting 5500 th label\n",
            "predicting 6000 th label\n",
            "predicting 6500 th label\n",
            "predicting 7000 th label\n",
            "predicting 7500 th label\n",
            "predicting 8000 th label\n",
            "predicting 8500 th label\n",
            "predicting 9000 th label\n",
            "predicting 9500 th label\n",
            "====================\n",
            "0.9264\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U37sP_ToeHbg",
        "colab_type": "code",
        "outputId": "920bc643-6b33-4530-bd73-8d7a21f2a310",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test = ['mnist_basic','mnist_rotation_back_image_new','mnist_rotation_new']\n",
        "for item in test:\n",
        "  print(item)\n",
        "  do_it(item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mnist_basic\n",
            "====================\n",
            "calculating L1_stage filters\n",
            "0 th picture\n",
            "shape of L1_stage filters: (8, 7, 7)\n",
            "shape of L1 stage convolution results: (80000, 28, 28)\n",
            "====================\n",
            "calculating L2_stage filters\n",
            "0 th picture\n",
            "10000 th picture\n",
            "20000 th picture\n",
            "30000 th picture\n",
            "40000 th picture\n",
            "50000 th picture\n",
            "60000 th picture\n",
            "70000 th picture\n",
            "shape of L2_stage filters: (8, 7, 7)\n",
            "====================\n",
            "extracting 0 th feature\n",
            "extracting 1000 th feature\n",
            "extracting 2000 th feature\n",
            "extracting 3000 th feature\n",
            "extracting 4000 th feature\n",
            "extracting 5000 th feature\n",
            "extracting 6000 th feature\n",
            "extracting 7000 th feature\n",
            "extracting 8000 th feature\n",
            "extracting 9000 th feature\n",
            "length of feature: 32768\n",
            "====================\n",
            "features extracted, SVM training\n",
            "====================\n",
            "predicting 0 th label\n",
            "predicting 500 th label\n",
            "predicting 1000 th label\n",
            "predicting 1500 th label\n",
            "predicting 2000 th label\n",
            "predicting 2500 th label\n",
            "predicting 3000 th label\n",
            "predicting 3500 th label\n",
            "predicting 4000 th label\n",
            "predicting 4500 th label\n",
            "predicting 5000 th label\n",
            "predicting 5500 th label\n",
            "predicting 6000 th label\n",
            "predicting 6500 th label\n",
            "predicting 7000 th label\n",
            "predicting 7500 th label\n",
            "predicting 8000 th label\n",
            "predicting 8500 th label\n",
            "predicting 9000 th label\n",
            "predicting 9500 th label\n",
            "====================\n",
            "0.9821\n",
            "mnist_rotation_back_image_new\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-26-c4eb692fa53e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m   \u001b[0mdo_it\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-22-4ab532cd4767>\u001b[0m in \u001b[0;36mdo_it\u001b[0;34m(dir_name)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mdo_it\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0mtrain_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_mnist_2_0\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtrain_labels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0mtest_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_images\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-5-bad90d9fdc9b>\u001b[0m in \u001b[0;36mload_mnist_2_0\u001b[0;34m(dir_name)\u001b[0m\n\u001b[1;32m      6\u001b[0m   \u001b[0mtest_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdirname\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'mnist_2.0'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdir_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m   \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m   \u001b[0mtest_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloadtxt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mloadtxt\u001b[0;34m(fname, dtype, comments, delimiter, converters, skiprows, usecols, unpack, ndmin, encoding, max_rows)\u001b[0m\n\u001b[1;32m    979\u001b[0m             \u001b[0mfname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_is_string_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 981\u001b[0;31m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_datasource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    982\u001b[0m             \u001b[0mfencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'latin1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m             \u001b[0mfh\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(path, mode, destpath, encoding, newline)\u001b[0m\n\u001b[1;32m    267\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    268\u001b[0m     \u001b[0mds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mDataSource\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdestpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 269\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnewline\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnewline\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    270\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/numpy/lib/_datasource.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, path, mode, encoding, newline)\u001b[0m\n\u001b[1;32m    621\u001b[0m                                       encoding=encoding, newline=newline)\n\u001b[1;32m    622\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 623\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mIOError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s not found.\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    624\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOSError\u001b[0m: /content/drive/My Drive/pcanet/mnist_2.0/mnist_rotation_back_image_new/mnist_rotation_back_image_new_train.amat not found."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qyY7D03IKEr",
        "colab_type": "code",
        "outputId": "080d21fb-625a-43e1-a77c-efc52a07ca86",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "test2 = ['mnist_rotation_back_image_new','mnist_rotation_new']\n",
        "for item in test2:\n",
        "  print(item)\n",
        "  do_it(item)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "mnist_rotation_back_image_new\n",
            "====================\n",
            "calculating L1_stage filters\n",
            "0 th picture\n",
            "shape of L1_stage filters: (8, 7, 7)\n",
            "shape of L1 stage convolution results: (80000, 28, 28)\n",
            "====================\n",
            "calculating L2_stage filters\n",
            "0 th picture\n",
            "10000 th picture\n",
            "20000 th picture\n",
            "30000 th picture\n",
            "40000 th picture\n",
            "50000 th picture\n",
            "60000 th picture\n",
            "70000 th picture\n",
            "shape of L2_stage filters: (8, 7, 7)\n",
            "====================\n",
            "extracting 0 th feature\n",
            "extracting 1000 th feature\n",
            "extracting 2000 th feature\n",
            "extracting 3000 th feature\n",
            "extracting 4000 th feature\n",
            "extracting 5000 th feature\n",
            "extracting 6000 th feature\n",
            "extracting 7000 th feature\n",
            "extracting 8000 th feature\n",
            "extracting 9000 th feature\n",
            "length of feature: 32768\n",
            "====================\n",
            "features extracted, SVM training\n",
            "====================\n",
            "predicting 0 th label\n",
            "predicting 500 th label\n",
            "predicting 1000 th label\n",
            "predicting 1500 th label\n",
            "predicting 2000 th label\n",
            "predicting 2500 th label\n",
            "predicting 3000 th label\n",
            "predicting 3500 th label\n",
            "predicting 4000 th label\n",
            "predicting 4500 th label\n",
            "predicting 5000 th label\n",
            "predicting 5500 th label\n",
            "predicting 6000 th label\n",
            "predicting 6500 th label\n",
            "predicting 7000 th label\n",
            "predicting 7500 th label\n",
            "predicting 8000 th label\n",
            "predicting 8500 th label\n",
            "predicting 9000 th label\n",
            "predicting 9500 th label\n",
            "====================\n",
            "0.5953\n",
            "mnist_rotation_new\n",
            "====================\n",
            "calculating L1_stage filters\n",
            "0 th picture\n",
            "shape of L1_stage filters: (8, 7, 7)\n",
            "shape of L1 stage convolution results: (80000, 28, 28)\n",
            "====================\n",
            "calculating L2_stage filters\n",
            "0 th picture\n",
            "10000 th picture\n",
            "20000 th picture\n",
            "30000 th picture\n",
            "40000 th picture\n",
            "50000 th picture\n",
            "60000 th picture\n",
            "70000 th picture\n",
            "shape of L2_stage filters: (8, 7, 7)\n",
            "====================\n",
            "extracting 0 th feature\n",
            "extracting 1000 th feature\n",
            "extracting 2000 th feature\n",
            "extracting 3000 th feature\n",
            "extracting 4000 th feature\n",
            "extracting 5000 th feature\n",
            "extracting 6000 th feature\n",
            "extracting 7000 th feature\n",
            "extracting 8000 th feature\n",
            "extracting 9000 th feature\n",
            "length of feature: 32768\n",
            "====================\n",
            "features extracted, SVM training\n",
            "====================\n",
            "predicting 0 th label\n",
            "predicting 500 th label\n",
            "predicting 1000 th label\n",
            "predicting 1500 th label\n",
            "predicting 2000 th label\n",
            "predicting 2500 th label\n",
            "predicting 3000 th label\n",
            "predicting 3500 th label\n",
            "predicting 4000 th label\n",
            "predicting 4500 th label\n",
            "predicting 5000 th label\n",
            "predicting 5500 th label\n",
            "predicting 6000 th label\n",
            "predicting 6500 th label\n",
            "predicting 7000 th label\n",
            "predicting 7500 th label\n",
            "predicting 8000 th label\n",
            "predicting 8500 th label\n",
            "predicting 9000 th label\n",
            "predicting 9500 th label\n",
            "====================\n",
            "0.9034\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
